{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:35.537606Z",
     "iopub.status.busy": "2023-12-19T07:38:35.536936Z",
     "iopub.status.idle": "2023-12-19T07:38:42.677785Z",
     "shell.execute_reply": "2023-12-19T07:38:42.676214Z",
     "shell.execute_reply.started": "2023-12-19T07:38:35.537579Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install tensorflow\n",
    "%pip install --upgrade 'gymnasium[atari]' 'gymnasium[accept-rom-license]' moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:42.679923Z",
     "iopub.status.busy": "2023-12-19T07:38:42.679649Z",
     "iopub.status.idle": "2023-12-19T07:38:45.538465Z",
     "shell.execute_reply": "2023-12-19T07:38:45.537619Z",
     "shell.execute_reply.started": "2023-12-19T07:38:42.679899Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import perf_counter\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "from glob import glob\n",
    "from gymnasium.wrappers import (\n",
    "    RecordVideo,\n",
    "    GrayScaleObservation,\n",
    "    ResizeObservation,\n",
    "    FrameStack,\n",
    "    NormalizeObservation,\n",
    ")\n",
    "from pathlib import Path\n",
    "from keras.layers import Conv2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.540213Z",
     "iopub.status.busy": "2023-12-19T07:38:45.539748Z",
     "iopub.status.idle": "2023-12-19T07:38:45.611055Z",
     "shell.execute_reply": "2023-12-19T07:38:45.609968Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.540190Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.613322Z",
     "iopub.status.busy": "2023-12-19T07:38:45.612837Z",
     "iopub.status.idle": "2023-12-19T07:38:45.619748Z",
     "shell.execute_reply": "2023-12-19T07:38:45.618750Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.613274Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_env(env_id=\"ALE/AirRaid-v5\", capture_video: bool = False) -> gym.Env:\n",
    "    \"\"\"Create an environment with some standard wrappers. These are similar to the wrappers used in the\n",
    "    Atari Preprocessing wrapper.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env_id : str, optional\n",
    "        Environment ID of the gym environment, by default \"ALE/AirRaid-v5\"\n",
    "    capture_video : bool, optional\n",
    "        If True, the environment will be recorded as a video every 50 episodes, by default False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gym.Env\n",
    "        Gym environment with wrappers applied\n",
    "    \"\"\"\n",
    "    if capture_video:\n",
    "        run_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "        env = RecordVideo(\n",
    "            env, f\"videos/{run_name}.mp4\", episode_trigger=lambda x: x % 50\n",
    "        )\n",
    "    else:\n",
    "        env = gym.make(env_id)\n",
    "    env = ResizeObservation(env, shape=84)\n",
    "    env = GrayScaleObservation(env)\n",
    "    env = NormalizeObservation(env)\n",
    "    env = FrameStack(env, 4)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.622480Z",
     "iopub.status.busy": "2023-12-19T07:38:45.622256Z",
     "iopub.status.idle": "2023-12-19T07:38:45.830103Z",
     "shell.execute_reply": "2023-12-19T07:38:45.829214Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.622460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model File Path\n",
    "run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_path = Path(\"models\")\n",
    "log_path = Path(\"logs\")\n",
    "\n",
    "# Define the state and action space sizes\n",
    "env = create_env()\n",
    "state, _ = env.reset()\n",
    "action_space = env.action_space.n  # 6 actions\n",
    "state_space = state.shape  # (4, 84, 84) 4 frames, 84x84 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.833886Z",
     "iopub.status.busy": "2023-12-19T07:38:45.833664Z",
     "iopub.status.idle": "2023-12-19T07:38:45.838463Z",
     "shell.execute_reply": "2023-12-19T07:38:45.837628Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.833865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_shape = state_space\n",
    "num_episodes = 500\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "discount_rate = 0.99\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.99\n",
    "update_target_network_steps = 10_000\n",
    "replay_memory = deque(maxlen=25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.840144Z",
     "iopub.status.busy": "2023-12-19T07:38:45.839757Z",
     "iopub.status.idle": "2023-12-19T07:38:45.845347Z",
     "shell.execute_reply": "2023-12-19T07:38:45.844504Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.840120Z"
    }
   },
   "outputs": [],
   "source": [
    "def log_episode_to_csv(episode_data: dict):\n",
    "    print(episode_data)\n",
    "    # Check if file exists to determine if header is needed\n",
    "    filename = log_path / f\"{run_id}.csv\"\n",
    "    file_exists = Path(filename).exists()\n",
    "\n",
    "    # Open the file in append mode\n",
    "    with open(filename, \"a\", newline=\"\") as csvfile:\n",
    "        # Create a writer object\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=episode_data.keys())\n",
    "\n",
    "        # Write the header only if the file didn't exist\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Write the episode data\n",
    "        writer.writerow(episode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.847225Z",
     "iopub.status.busy": "2023-12-19T07:38:45.846902Z",
     "iopub.status.idle": "2023-12-19T07:38:45.855054Z",
     "shell.execute_reply": "2023-12-19T07:38:45.854007Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.847201Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape: tuple, output_shape: int) -> tf.keras.Model:\n",
    "    \"\"\"Create a convolutional neural network model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tf.keras.Model\n",
    "        A sequential model with the following layers:\n",
    "        - Conv2D with 32 filters, kernel size of 8, stride of 4, and relu activation\n",
    "        - Conv2D with 64 filters, kernel size of 4, stride of 2, and relu activation\n",
    "        - Conv2D with 64 filters, kernel size of 3, stride of 1, and relu activation\n",
    "        - Flatten layer\n",
    "        - Dense layer with 4096 units and relu activation\n",
    "        - Dense layer with 512 units and relu activation\n",
    "        - Dense layer with 5 units and linear activation\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            Conv2D(\n",
    "                32, (8, 8), strides=(4, 4), activation=\"relu\", input_shape=input_shape\n",
    "            ),\n",
    "            Conv2D(64, (4, 4), strides=(2, 2), activation=\"relu\"),\n",
    "            Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\"),\n",
    "            Flatten(),\n",
    "            Dense(4096, activation=\"relu\"),\n",
    "            Dense(512, activation=\"relu\"),\n",
    "            Dense(output_shape, activation=\"linear\"),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:45.865620Z",
     "iopub.status.busy": "2023-12-19T07:38:45.865401Z",
     "iopub.status.idle": "2023-12-19T07:38:47.560962Z",
     "shell.execute_reply": "2023-12-19T07:38:47.559748Z",
     "shell.execute_reply.started": "2023-12-19T07:38:45.865601Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (\n",
    "    *state_space,\n",
    "    1,\n",
    ")  # (175, 41, 1) we need to add a channel dimension to the input shape\n",
    "model = create_model(input_shape, action_space)\n",
    "target_model = create_model(input_shape, action_space)\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss=\"mse\"\n",
    ")\n",
    "\n",
    "# Initially, set the target model weights equal to the model's weights\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:47.562553Z",
     "iopub.status.busy": "2023-12-19T07:38:47.562265Z",
     "iopub.status.idle": "2023-12-19T07:38:47.572360Z",
     "shell.execute_reply": "2023-12-19T07:38:47.571651Z",
     "shell.execute_reply.started": "2023-12-19T07:38:47.562523Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: tf.keras.Model,\n",
    "    target_model: tf.keras.Model,\n",
    "    minibatch: np.ndarray,\n",
    "    discount_rate: float,\n",
    "):\n",
    "    \"\"\"Train the model using the minibatch of transitions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : tf.keras.Model\n",
    "        The main neural network model that is being trained.\n",
    "    target_model : tf.keras.Model\n",
    "        The target neural network model that is used to predict the Q-values for the next state.\n",
    "    minibatch : np.ndarray\n",
    "        The minibatch of transitions to train the model on.\n",
    "    discount_rate : float\n",
    "        The discount rate to use when calculating the Q-values.\n",
    "    \"\"\"\n",
    "    # Extract information from the minibatch\n",
    "    states = np.array([transition[0] for transition in minibatch])  # (64, 175, 41)\n",
    "    actions = np.array([transition[1] for transition in minibatch])  # (64,)\n",
    "    rewards = np.array([transition[2] for transition in minibatch])  # (64,)\n",
    "    next_states = np.array([transition[3] for transition in minibatch])  # (64, 175, 41)\n",
    "    dones = np.array([transition[4] for transition in minibatch])  # (64,)\n",
    "\n",
    "    # Predict Q-values for starting state and next state\n",
    "    current_q_values = model.predict(states, verbose=0)\n",
    "    next_q_values = target_model.predict(next_states, verbose=0)\n",
    "\n",
    "    target_q_values = current_q_values.copy()\n",
    "    for i in range(len(minibatch)):\n",
    "        if dones[i]:\n",
    "            # If the episode is done, the Q-value is simply the reward\n",
    "            target_q_values[i][actions[i]] = rewards[i]\n",
    "        else:\n",
    "            # If the episode is not done, the Q-value is the reward plus the discounted predicted reward\n",
    "            target_q_values[i][actions[i]] = rewards[i] + discount_rate * np.amax(\n",
    "                next_q_values[i]\n",
    "            )\n",
    "\n",
    "    model.fit(states, target_q_values, epochs=1, verbose=0, batch_size=len(minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:47.573615Z",
     "iopub.status.busy": "2023-12-19T07:38:47.573395Z",
     "iopub.status.idle": "2023-12-19T07:38:47.577894Z",
     "shell.execute_reply": "2023-12-19T07:38:47.577234Z",
     "shell.execute_reply.started": "2023-12-19T07:38:47.573595Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model: tf.keras.Model, name_prefix: str, episode: int):\n",
    "    \"\"\"Save the model weights to the specified path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : tf.keras.Model\n",
    "        The model to save the weights of.\n",
    "    name_prefix : str\n",
    "        Prefix to use when saving the model weights.\n",
    "    episode : int\n",
    "        The episode number to use when saving the model weights.\n",
    "    \"\"\"\n",
    "    model.save_weights(model_path / f\"{name_prefix}_episode_{episode}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:47.580332Z",
     "iopub.status.busy": "2023-12-19T07:38:47.580110Z",
     "iopub.status.idle": "2023-12-19T07:38:47.583890Z",
     "shell.execute_reply": "2023-12-19T07:38:47.583120Z",
     "shell.execute_reply.started": "2023-12-19T07:38:47.580313Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model() -> int:\n",
    "    \"\"\"Load the model weights from the specified path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    episode : int | None\n",
    "        The episode to load the model weights from. If None, then the latest model weights will be loaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The episode number that the model weights were loaded from.\n",
    "    \"\"\"\n",
    "    glob_path = model_path / \"*.h5\"\n",
    "    model_files = glob(str(glob_path))\n",
    "    episode = 0\n",
    "    if model_files:\n",
    "        episode = max(\n",
    "            [int(Path(model_file).stem.split(\"_\")[-1]) for model_file in model_files]\n",
    "        )\n",
    "        print(f\"Loading models from episode {episode}...\")\n",
    "        model.load_weights(model_path / f\"main_episode_{episode}.h5\")\n",
    "        target_model.load_weights(model_path / f\"target_episode_{episode}.h5\")\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T07:38:47.585345Z",
     "iopub.status.busy": "2023-12-19T07:38:47.585075Z"
    }
   },
   "outputs": [],
   "source": [
    "step_counter = 0\n",
    "start_episode = load_model()\n",
    "\n",
    "for episode in range(start_episode, num_episodes + 1):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    start_time = perf_counter()\n",
    "    episode_reward = 0\n",
    "    exploitation_steps = 0\n",
    "    exploration_steps = 0\n",
    "    while not done:\n",
    "        # Exploration-exploitation trade-off\n",
    "        exploration_threshold = random.uniform(0, 1)\n",
    "        # If exploration_threshold > exploration_rate, then exploitation\n",
    "        if exploration_threshold > exploration_rate:\n",
    "            exploitation_steps += 1\n",
    "            q_values = model.predict(\n",
    "                np.expand_dims(state, axis=0), verbose=0\n",
    "            )  # add batch dimension\n",
    "            action = np.argmax(q_values[0])\n",
    "        else:\n",
    "            exploration_steps += 1\n",
    "            action = env.action_space.sample()\n",
    "\n",
    "        # Increment the step counter\n",
    "        step_counter += 1\n",
    "\n",
    "        # Take action and observe the next state and reward\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Add the experience to replay memory\n",
    "        replay_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        # Sample a minibatch from the replay buffer\n",
    "        if len(replay_memory) > batch_size:\n",
    "            minibatch = random.sample(replay_memory, batch_size)\n",
    "            # Train the model on the minibatch\n",
    "            train(model, target_model, minibatch, discount_rate)\n",
    "\n",
    "        if step_counter % update_target_network_steps == 0:\n",
    "            # Update the the target network with new weights\n",
    "            target_model.set_weights(model.get_weights())\n",
    "\n",
    "    # End of episode\n",
    "    # Decay the exploration rate\n",
    "    exploration_rate = max(\n",
    "        min_exploration_rate, exploration_rate * exploration_decay_rate\n",
    "    )\n",
    "    log_episode_to_csv(\n",
    "        {\n",
    "            \"episode\": episode,\n",
    "            \"duration\": f\"{perf_counter() - start_time:.2f}\",\n",
    "            \"exploration_rate\": f\"{exploration_rate:.2f}\",\n",
    "            \"exploitation_steps\": exploitation_steps,\n",
    "            \"exploration_steps\": exploration_steps,\n",
    "            \"total_steps\": step_counter,\n",
    "            \"episode_reward\": episode_reward,\n",
    "        }\n",
    "    )\n",
    "    if episode % 50 == 0:\n",
    "        # Save the model weights every 50 episodes\n",
    "        save_model(model, \"main\", episode)\n",
    "        save_model(target_model, \"target\", episode)\n",
    "\n",
    "# Save the final model weights\n",
    "save_model(model, \"main\", episode)\n",
    "save_model(target_model, \"target\", episode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
